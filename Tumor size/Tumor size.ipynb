{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10735917,"sourceType":"datasetVersion","datasetId":6656772}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from PIL import Image\n","\n","class TumorSizeCalculator(nn.Module):\n","    def __init__(self):\n","        super(TumorSizeCalculator, self).__init__()\n","        # Define preprocessing transformations\n","        self.transform = transforms.Compose([\n","            transforms.ToTensor(),  # Converts to range [0.0, 1.0]\n","        ])\n","\n","    def forward(self, x):\n","        # Input x: PIL Image or file path\n","        if isinstance(x, str):\n","            x = Image.open(x)\n","\n","        # Convert to grayscale if needed and transform to tensor\n","        if isinstance(x, Image.Image):\n","            x = x.convert('L')  # Convert to grayscale\n","            x = self.transform(x)\n","\n","        # Calculate tumor size (white pixels proportion)\n","        tumor_size = torch.mean(x)  # White pixels are 1.0, black are 0.0\n","\n","        return tumor_size.item()"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T21:47:09.312149Z","iopub.execute_input":"2025-02-12T21:47:09.312452Z","iopub.status.idle":"2025-02-12T21:47:15.818650Z","shell.execute_reply.started":"2025-02-12T21:47:09.312423Z","shell.execute_reply":"2025-02-12T21:47:15.817812Z"},"id":"XH44FG5b961x"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Initialize model\n","    tumor_calculator = TumorSizeCalculator()\n","\n","    # Process image (either file path or PIL Image)\n","    image_path = \"/kaggle/input/mask-bla/Tr-me_0010_m.jpg\"\n","    size = tumor_calculator(image_path)\n","\n","    # print(f\"Tumor size proportion: {size:.4f}\")\n","    print(f\"Tumor size percentage: {size * 100:.2f}%\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T21:47:15.819635Z","iopub.execute_input":"2025-02-12T21:47:15.819960Z","iopub.status.idle":"2025-02-12T21:47:15.953522Z","shell.execute_reply.started":"2025-02-12T21:47:15.819939Z","shell.execute_reply":"2025-02-12T21:47:15.952332Z"},"id":"AmPkDNC19611","outputId":"7d5907ab-b040-4f1a-d92b-405447349709"},"outputs":[{"name":"stdout","text":"Tumor size proportion: 0.0321\nTumor size percentage: 3.21%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["# Save the entire model\n","torch.save(tumor_calculator, 'tumor_size_model.pth')\n","\n","# Alternatively, save just the state dictionary (though not strictly necessary for this simple model)\n","# torch.save(tumor_calculator.state_dict(), 'tumor_size_model_state.pth')"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T21:49:09.720699Z","iopub.execute_input":"2025-02-12T21:49:09.721012Z","iopub.status.idle":"2025-02-12T21:49:09.725712Z","shell.execute_reply.started":"2025-02-12T21:49:09.720989Z","shell.execute_reply":"2025-02-12T21:49:09.724761Z"},"id":"ajoGN5m_9613"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(\"model saved\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T21:49:31.418539Z","iopub.execute_input":"2025-02-12T21:49:31.418811Z","iopub.status.idle":"2025-02-12T21:49:31.422749Z","shell.execute_reply.started":"2025-02-12T21:49:31.418793Z","shell.execute_reply":"2025-02-12T21:49:31.421997Z"},"id":"L89pwki09613","outputId":"58721e69-3ad0-4d01-8fb4-bccbf143a9e6"},"outputs":[{"name":"stdout","text":"model saved\n","output_type":"stream"}],"execution_count":null}]}